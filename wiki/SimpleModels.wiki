#summary This wiki summarizes all results we can get for simple models

= Introduction =

First install chemev using the installation instructions (see the main page).

= Simple models =

== non-gaussian ==

Execute
{{{
cd chemev/calc/halo_nongaussian
python fit.py
}}}

Currently, the simplex method works much better than bfgs. Both for !ExpLogistics and !ReflectLogistics the bfgs is slower.

Change the parameter `iter` at line 88 from 5 to something bigger, like 50 or 100 to get a better fit. The initial values of all parameters are randomized, so you can rerun the fit many times to see how it converges. 

At the end it will print "metallicity vs age" and "sfr vs age" for both the (random) initial state and the converged fit.

I also tried simulated annealing, with no more success. It's slower than simplex. And simplex by itself is terribly slow and gets stuck at a different "fit" every time. But the annealing and bfgs behaves even worse.... Well, ill defined problem.

== brute force ==

By trying random values of all parameters in all iterations, the best fit is:

{{{
iteration: likelihood

1: -530468.700881
3: -533037.766045
14: -536549.618184
22: -540911.195635
81: -541088.061026
241: -544192.5148
447: -546756.018438
}}}

After this, it won't improve more (even in an hour).

== bfgs ==

The best fit was:
{{{
At iterate   12    f= -5.49110E+05    |proj g|=  7.97344E+01
--grad 17: 3.84748005867
--grad 18: 3.83931493759

At iterate   13    f= -5.49122E+05    |proj g|=  8.76562E+01
--grad 19: 3.90191888809

At iterate   14    f= -5.49128E+05    |proj g|=  9.49688E+01

.....

At iterate   26    f= -5.49200E+05    |proj g|=  1.48344E+02
--grad 36: 3.83281207085

At iterate   27    f= -5.49205E+05    |proj g|=  1.71609E+02
--grad 37: 3.84526515007

At iterate   28    f= -5.49211E+05    |proj g|=  7.54453E+01

}}}

And some other run:

{{{
At iterate    0    f= -5.07055E+05    |proj g|=  2.28011E+03
--grad 2: 2.35150790215

At iterate    1    f= -5.10541E+05    |proj g|=  2.13931E+03
--grad 3: 2.35605692863

At iterate    2    f= -5.18564E+05    |proj g|=  1.01841E+03
--grad 4: 2.35718607903

At iterate    3    f= -5.20395E+05    |proj g|=  2.83711E+02
--grad 5: 2.3593480587

....

At iterate   54    f= -5.21368E+05    |proj g|=  2.65625E-01

}}}

another run:
{{{
At iterate    0    f= -5.24782E+05    |proj g|=  4.98662E+03
--grad 2: 3.83779811859
--grad 3: 3.84446811676

At iterate    1    f= -5.43362E+05    |proj g|=  4.57234E+02
--grad 4: 3.85416007042

At iterate    2    f= -5.43630E+05    |proj g|=  3.54672E+02
--grad 5: 3.82967615128
--grad 6: 3.82982206345

At iterate    3    f= -5.44465E+05    |proj g|=  8.15812E+02
--grad 7: 3.83754587173

At iterate    4    f= -5.45047E+05    |proj g|=  2.27594E+02
--grad 8: 3.8793900013

....

At iterate   38    f= -5.46308E+05    |proj g|=  3.76484E+01
}}}

As you can see, it's very important where the fit starts.

== simplex ==

{{{
henry: -534981.173797 tom: 54193.2791883 iter: 1
henry: -537423.892667 tom: 49307.8414476 iter: 13
henry: -544302.382697 tom: 35550.8613883 iter: 14
henry: -547265.684768 tom: 29624.2572457 iter: 17
henry: -547421.766356 tom: 29312.0940701 iter: 19
henry: -548733.514434 tom: 26688.5979142 iter: 20
henry: -549006.209884 tom: 26143.2070146 iter: 27
henry: -549012.652118 tom: 26130.3225472 iter: 33
henry: -549173.553862 tom: 25808.519058 iter: 35
henry: -549856.397806 tom: 24442.8311699 iter: 37
henry: -549938.406718 tom: 24278.8133469 iter: 39
henry: -550314.086327 tom: 23527.4541276 iter: 46
henry: -550331.251725 tom: 23493.1233332 iter: 49
henry: -550403.638676 tom: 23348.3494299 iter: 50
henry: -550893.948665 tom: 22367.7294526 iter: 61
henry: -551115.179602 tom: 21925.2675781 iter: 67
henry: -551124.583559 tom: 21906.4596641 iter: 85
henry: -551148.320722 tom: 21858.9853381 iter: 91
henry: -551150.262225 tom: 21855.1023329 iter: 98
henry: -551150.641107 tom: 21854.3445692 iter: 99
}}}